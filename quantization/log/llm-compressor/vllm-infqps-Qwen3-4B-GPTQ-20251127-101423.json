{"date": "20251127-101423", "endpoint_type": "vllm", "backend": "vllm", "label": null, "model_id": "Qwen3-4B-GPTQ", "tokenizer_id": "/home/bocchi/Work/Quantization_Demo/quantization/gptq/Qwen3-4B-W4A16-GPTQSAMPLES512", "num_prompts": 100, "request_rate": "inf", "burstiness": 1.0, "max_concurrency": null, "duration": 16.2092684570016, "completed": 100, "failed": 0, "total_input_tokens": 23260, "total_output_tokens": 22061, "request_throughput": 6.169309877572234, "request_goodput": null, "output_throughput": 1361.0114520912105, "total_token_throughput": 2795.992929614512, "max_output_tokens_per_s": 2818.0, "max_concurrent_requests": 100, "mean_ttft_ms": 2415.2042795600573, "median_ttft_ms": 2585.528988999613, "std_ttft_ms": 1320.1690751510887, "p99_ttft_ms": 4337.521523011128, "mean_tpot_ms": 70.07050690143302, "median_tpot_ms": 34.29418840577875, "std_tpot_ms": 87.49790481251229, "p99_tpot_ms": 372.65814317942693, "mean_itl_ms": 27.821988370127748, "median_itl_ms": 21.262738000586978, "std_itl_ms": 51.942865936029776, "p99_itl_ms": 376.5376954804742}